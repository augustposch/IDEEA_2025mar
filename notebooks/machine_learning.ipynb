{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af4c8e1a-ecc7-44b2-a3b0-59ba5eb5ac2e",
   "metadata": {},
   "source": [
    "Machine learning, Baseline AI downscaler\n",
    "\n",
    "August Posch --- March-May 2025\n",
    "\n",
    "In this notebook:\n",
    "- First, using reanalysis inputs and observed precip labels, train on 1975-1994 and validate on 1995-2014.\n",
    "- Try various hyperparameterizations of the above and choose the one with the best MAE-APM score on the validation set.\n",
    "- Visualize the implied APM and GEV curve from the best model predictions and from the observations.\n",
    "\n",
    "Next to-do:\n",
    "- Then, using GCM inputs, do extra validation on 1995-2014 and also predict in the future period 2031-2050.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f52ae7c0-efa0-43e8-b417-ed0a7f0800c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'X_train_rean': '../data/ML_ready/boston_ERA5_1975_1994.npy',\n",
    "    'y_train': '../data/ML_ready/gba_livneh_unsplit_1975_1994.npy',\n",
    "    'X_val_rean': '../data/ML_ready/boston_ERA5_1995_2014.npy',\n",
    "    'y_val': '../data/ML_ready/gba_livneh_unsplit_1995_2014.npy',\n",
    "    'X_val_gcm': '../data/ML_ready/bos_CESM2_val.npy',\n",
    "    'X_fut_gcm': '../data/ML_ready/bos_CESM2_fut.npy'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be62a102-ecf1-428a-8777-9646c9c28fd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.stats import genextreme as gev\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25ed25e4-32d8-4556-9c36-34a422e3afc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rean = np.load(parameters['X_train_rean'], allow_pickle=True)\n",
    "y_train = np.load(parameters['y_train'], allow_pickle=True)\n",
    "X_val_rean = np.load(parameters['X_val_rean'], allow_pickle=True)\n",
    "y_val = np.load(parameters['y_val'], allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc12b48-1c71-4b79-8404-92b30a86e262",
   "metadata": {},
   "source": [
    "Define all the hyperparameterizations we will search over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "761fb2ac-7f97-4167-9df0-5e9b58f25735",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperpzns_bank = {}\n",
    "increment = 0\n",
    "for n_estimators in [100, 300]:\n",
    "    for max_features in [12, 9, 6]:\n",
    "        for min_samples_split in [2, 4]:\n",
    "            for bootstrap in [False, True]:\n",
    "\n",
    "                increment += 1\n",
    "                three_digit = str(increment).zfill(3)\n",
    "                hyperpzns_bank['RF'+three_digit] = {\n",
    "                    'n_estimators': n_estimators,\n",
    "                    'max_features': max_features,\n",
    "                    'bootstrap': bootstrap,\n",
    "                    'min_samples_split': min_samples_split,\n",
    "                    'random_state': 19\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a0fe6e-fcab-4d96-b85d-82cb30bbc728",
   "metadata": {},
   "source": [
    "Set up a dictionary of untrained models (scikit-learn estimator objects)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "123a9785-0dbc-42fe-b80f-82eb23f008e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "untrained_models = {}\n",
    "for name, spec in hyperpzns_bank.items():\n",
    "    untrained_models[name] = RandomForestRegressor(**spec) # these are sklearn model objects (estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344d4f71-8299-4190-b957-c33a2de26108",
   "metadata": {},
   "source": [
    "Define a funciton `fit_predict_rean()`, which trains/fits a model based on reanalysis data, prints some validation scores, and returns the trained model and the MAE-APM score. (Note: If you hold constant the random seed, the hyperparameterization, and the training dataset, then you always end up with the same model parameters a.k.a. model specification.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17513a03-ebf9-4a93-af66-ecfd11524c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict_rean(model, X_train_rean, y_train, X_val_rean, y_val):\n",
    "    \n",
    "    print('> Fitting the model on the training set')\n",
    "    model.fit(X_train_rean, y_train)\n",
    "    print('> Predicting on the validation set')\n",
    "    pred = model.predict(X_val_rean)\n",
    "    print('> Recording performance metrics')\n",
    "    \n",
    "    # Mean Absolute Error of all days 1995-2014\n",
    "    error =  pred - y_val\n",
    "    mae = np.mean(np.abs(error))\n",
    "    print('--> Mean Absolute Error:', np.round(mae,2), 'mm')\n",
    "    \n",
    "    # Mean Absolute Error of Annual Precipitation Maxima 1995-2014\n",
    "    pred_apm = []\n",
    "    y_val_apm = []\n",
    "    dpy = [365,366,365,365]*5 # days per year 1995 to 2014\n",
    "    for year in range(20):\n",
    "        idx_yearstart = sum(dpy[:year])\n",
    "        idx_nextyearstart = sum(dpy[:year+1])\n",
    "        pred_maxthisyear = max(pred[idx_yearstart:idx_nextyearstart])\n",
    "        y_val_maxthisyear = max(y_val[idx_yearstart:idx_nextyearstart])\n",
    "        pred_apm.append(pred_maxthisyear)\n",
    "        y_val_apm.append(y_val_maxthisyear)\n",
    "\n",
    "    pred_apm = np.array(pred_apm)\n",
    "    y_val_apm = np.array(y_val_apm)\n",
    "    \n",
    "    error_apm =  pred_apm - y_val_apm\n",
    "    mae_apm = np.mean(np.abs(error_apm))\n",
    "    print('--> MAE of Annual Precip Max:', np.round(mae_apm,2), 'mm')\n",
    "    \n",
    "    # GEV curves and implied flood levels\n",
    "    shape, loc, scale = gev.fit(y_val_apm)\n",
    "    print('--> Return levels in millimeters, GEV of observations 1995-2014:')\n",
    "    one_pct_level_obs, four_pct_level_obs = gev.isf(1/100,shape,loc,scale), gev.isf(1/25,shape,loc,scale)\n",
    "    print('----> 1/100 year level:', np.round(one_pct_level_obs))\n",
    "    print('----> 1/25 year level:', np.round(four_pct_level_obs))\n",
    "    \n",
    "    shape, loc, scale = gev.fit(pred_apm)\n",
    "    print('--> Return levels in millimeters, GEV of ML prediction from reanalysis 1995-2014:')\n",
    "    one_pct_level_pred, four_pct_level_pred = gev.isf(1/100,shape,loc,scale), gev.isf(1/25,shape,loc,scale)\n",
    "    print('----> 1/100 year level:', np.round(one_pct_level_pred))\n",
    "    print('----> 1/25 year level:', np.round(four_pct_level_pred))\n",
    "\n",
    "    return model, mae_apm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef02c113-f380-4f10-ad90-e3d6a9222c94",
   "metadata": {},
   "source": [
    "Train with all the different hyperparameterizations; record trained models and their scores. (This took a couple hours on August's laptop.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8c0d27-8dd0-43c8-8cc7-26e319a03b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: RF001\n",
      "> Fitting the model on the training set\n",
      "> Predicting on the validation set\n",
      "> Recording performance metrics\n",
      "--> Mean Absolute Error: 3.82 mm\n",
      "--> MAE of Annual Precip Max: 20.46 mm\n",
      "--> Return levels in millimeters, GEV of observations 1995-2014:\n",
      "----> 1/100 year level: 112.0\n",
      "----> 1/25 year level: 103.0\n",
      "--> Return levels in millimeters, GEV of ML prediction from reanalysis 1995-2014:\n",
      "----> 1/100 year level: 75.0\n",
      "----> 1/25 year level: 75.0\n",
      "Model Name: RF002\n",
      "> Fitting the model on the training set\n",
      "> Predicting on the validation set\n",
      "> Recording performance metrics\n",
      "--> Mean Absolute Error: 3.06 mm\n",
      "--> MAE of Annual Precip Max: 33.69 mm\n",
      "--> Return levels in millimeters, GEV of observations 1995-2014:\n",
      "----> 1/100 year level: 112.0\n",
      "----> 1/25 year level: 103.0\n",
      "--> Return levels in millimeters, GEV of ML prediction from reanalysis 1995-2014:\n",
      "----> 1/100 year level: 56.0\n",
      "----> 1/25 year level: 50.0\n",
      "Model Name: RF003\n",
      "> Fitting the model on the training set\n",
      "> Predicting on the validation set\n",
      "> Recording performance metrics\n",
      "--> Mean Absolute Error: 3.81 mm\n",
      "--> MAE of Annual Precip Max: 20.8 mm\n",
      "--> Return levels in millimeters, GEV of observations 1995-2014:\n",
      "----> 1/100 year level: 112.0\n",
      "----> 1/25 year level: 103.0\n",
      "--> Return levels in millimeters, GEV of ML prediction from reanalysis 1995-2014:\n",
      "----> 1/100 year level: 95.0\n",
      "----> 1/25 year level: 82.0\n",
      "Model Name: RF004\n",
      "> Fitting the model on the training set\n",
      "> Predicting on the validation set\n",
      "> Recording performance metrics\n",
      "--> Mean Absolute Error: 3.06 mm\n",
      "--> MAE of Annual Precip Max: 33.87 mm\n",
      "--> Return levels in millimeters, GEV of observations 1995-2014:\n",
      "----> 1/100 year level: 112.0\n",
      "----> 1/25 year level: 103.0\n",
      "--> Return levels in millimeters, GEV of ML prediction from reanalysis 1995-2014:\n",
      "----> 1/100 year level: 55.0\n",
      "----> 1/25 year level: 49.0\n",
      "Model Name: RF005\n",
      "> Fitting the model on the training set\n",
      "> Predicting on the validation set\n",
      "> Recording performance metrics\n",
      "--> Mean Absolute Error: 3.15 mm\n",
      "--> MAE of Annual Precip Max: 29.54 mm\n",
      "--> Return levels in millimeters, GEV of observations 1995-2014:\n",
      "----> 1/100 year level: 112.0\n",
      "----> 1/25 year level: 103.0\n",
      "--> Return levels in millimeters, GEV of ML prediction from reanalysis 1995-2014:\n",
      "----> 1/100 year level: 63.0\n",
      "----> 1/25 year level: 57.0\n",
      "Model Name: RF006\n",
      "> Fitting the model on the training set\n",
      "> Predicting on the validation set\n",
      "> Recording performance metrics\n",
      "--> Mean Absolute Error: 3.05 mm\n",
      "--> MAE of Annual Precip Max: 35.08 mm\n",
      "--> Return levels in millimeters, GEV of observations 1995-2014:\n",
      "----> 1/100 year level: 112.0\n",
      "----> 1/25 year level: 103.0\n",
      "--> Return levels in millimeters, GEV of ML prediction from reanalysis 1995-2014:\n",
      "----> 1/100 year level: 58.0\n",
      "----> 1/25 year level: 49.0\n",
      "Model Name: RF007\n",
      "> Fitting the model on the training set\n",
      "> Predicting on the validation set\n",
      "> Recording performance metrics\n",
      "--> Mean Absolute Error: 3.13 mm\n",
      "--> MAE of Annual Precip Max: 29.57 mm\n",
      "--> Return levels in millimeters, GEV of observations 1995-2014:\n",
      "----> 1/100 year level: 112.0\n",
      "----> 1/25 year level: 103.0\n",
      "--> Return levels in millimeters, GEV of ML prediction from reanalysis 1995-2014:\n",
      "----> 1/100 year level: 64.0\n",
      "----> 1/25 year level: 58.0\n",
      "Model Name: RF008\n",
      "> Fitting the model on the training set\n",
      "> Predicting on the validation set\n",
      "> Recording performance metrics\n",
      "--> Mean Absolute Error: 3.04 mm\n",
      "--> MAE of Annual Precip Max: 34.35 mm\n",
      "--> Return levels in millimeters, GEV of observations 1995-2014:\n",
      "----> 1/100 year level: 112.0\n",
      "----> 1/25 year level: 103.0\n",
      "--> Return levels in millimeters, GEV of ML prediction from reanalysis 1995-2014:\n",
      "----> 1/100 year level: 51.0\n",
      "----> 1/25 year level: 48.0\n",
      "Model Name: RF009\n",
      "> Fitting the model on the training set\n",
      "> Predicting on the validation set\n",
      "> Recording performance metrics\n",
      "--> Mean Absolute Error: 3.07 mm\n",
      "--> MAE of Annual Precip Max: 32.35 mm\n",
      "--> Return levels in millimeters, GEV of observations 1995-2014:\n",
      "----> 1/100 year level: 112.0\n",
      "----> 1/25 year level: 103.0\n",
      "--> Return levels in millimeters, GEV of ML prediction from reanalysis 1995-2014:\n",
      "----> 1/100 year level: 57.0\n",
      "----> 1/25 year level: 52.0\n",
      "Model Name: RF010\n",
      "> Fitting the model on the training set\n"
     ]
    }
   ],
   "source": [
    "trained_models = {}\n",
    "scores = {}\n",
    "for name, untrained_model in untrained_models.items():\n",
    "    # (could add a check here to only train if it hasn't been trained before)\n",
    "    print('Model Name:', name)\n",
    "    trained_model, score = fit_predict_rean(untrained_model, X_train_rean, y_train, X_val_rean, y_val)\n",
    "    \n",
    "    trained_models[name] = trained_model\n",
    "    scores[name] = score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d2845f-6ba9-4524-b08d-695b5e396a1d",
   "metadata": {},
   "source": [
    "Identify best model and save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a4a4af-ccc7-4ce9-a858-803ae68a8724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Which model name had the highest score?\"\n",
    "name_of_best = min(scores, key=scores.get)\n",
    "print(f'The best model was {name_of_best}, achieving an MAE-APM of {scores[name_of_best]} mm')\n",
    "\n",
    "print('This model used the following hyperparameterizations:\\n', hyperpzns_bank[name_of_best])\n",
    "\n",
    "# Save the trained model\n",
    "path = '../trained_models/best_model.pkl'\n",
    "pickle.dump(trained_models[name_of_best], open(path, 'wb'), protocol=5) \n",
    "print('Trained model saved here:', path)\n",
    "\n",
    "# note about loading later - code looks like below\n",
    "# model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805e54cd-3c8f-442b-9360-ca2b36f6e1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_performance_rean(model, X_val_rean, y_val):\n",
    "    pred = model.predict(X_val_rean)\n",
    "    print('> Performance of the model with visuals.')\n",
    "    \n",
    "    # Mean Absolute Error of all days 1995-2014\n",
    "    error =  pred - y_val\n",
    "    mae = np.mean(np.abs(error))\n",
    "    print('--> Mean Absolute Error:', np.round(mae,2), 'mm')\n",
    "    \n",
    "    # Mean Absolute Error of Annual Precipitation Maxima 1995-2014\n",
    "    pred_apm = []\n",
    "    y_val_apm = []\n",
    "    dpy = [365,366,365,365]*5 # days per year 1995 to 2014\n",
    "    for year in range(20):\n",
    "        idx_yearstart = sum(dpy[:year])\n",
    "        idx_nextyearstart = sum(dpy[:year+1])\n",
    "        pred_maxthisyear = max(pred[idx_yearstart:idx_nextyearstart])\n",
    "        y_val_maxthisyear = max(y_val[idx_yearstart:idx_nextyearstart])\n",
    "        pred_apm.append(pred_maxthisyear)\n",
    "        y_val_apm.append(y_val_maxthisyear)\n",
    "\n",
    "    pred_apm = np.array(pred_apm)\n",
    "    y_val_apm = np.array(y_val_apm)\n",
    "\n",
    "    plt.bar(np.arange(1995,2015), pred_apm, width=-0.3, align='edge', color='orange', label='Predicted by model')\n",
    "    plt.bar(np.arange(1995,2015), y_val_apm, width=0.3, align='edge', color='green', label='Observed')\n",
    "    plt.xticks(ticks=np.arange(1995,2015), rotation=90)\n",
    "    plt.ylabel('Annual Precipitation Max (mm)')\n",
    "    plt.xlabel('Year')\n",
    "    plt.title('Predicted and observed Annual Precipitation Max')\n",
    "    plt.legend()\n",
    "    plt.savefig('../figures/APM_pred_obs.png')\n",
    "    plt.show()\n",
    "\n",
    "    error_apm =  pred_apm - y_val_apm\n",
    "    mae_apm = np.mean(np.abs(error_apm))\n",
    "    print('--> MAE of Annual Precip Max:', np.round(mae_apm,2), 'mm')\n",
    "    \n",
    "    # GEV curves and implied flood levels\n",
    "    \n",
    "    shape, loc, scale = gev.fit(y_val_apm)\n",
    "    print('--> Return levels in millimeters, GEV of observations 1995-2014:')\n",
    "    one_pct_level_obs, four_pct_level_obs = gev.isf(1/100,shape,loc,scale), gev.isf(1/25,shape,loc,scale)\n",
    "    print('----> 1/100 year level:', np.round(one_pct_level_obs))\n",
    "    print('----> 1/25 year level:', np.round(four_pct_level_obs))\n",
    "    # Plot that curve\n",
    "    pp = np.linspace(1/100, 0.85, 500) \n",
    "    xx = 1/pp\n",
    "    yy = gev.isf(pp, shape, loc, scale)\n",
    "    plt.plot(xx, yy, color='green', label='GEV of Observations')\n",
    "    \n",
    "    shape, loc, scale = gev.fit(pred_apm)\n",
    "    print('--> Return levels in millimeters, GEV of ML prediction from reanalysis 1995-2014:')\n",
    "    one_pct_level_pred, four_pct_level_pred = gev.isf(1/100,shape,loc,scale), gev.isf(1/25,shape,loc,scale)\n",
    "    print('----> 1/100 year level:', np.round(one_pct_level_pred))\n",
    "    print('----> 1/25 year level:', np.round(four_pct_level_pred))\n",
    "    # Plot that curve\n",
    "    pp = np.linspace(1/100, 0.85, 500) \n",
    "    xx = 1/pp\n",
    "    yy = gev.isf(pp, shape, loc, scale)\n",
    "    plt.plot(xx, yy, color='orange', label='GEV of ML Prediction')\n",
    "    plt.ylabel('Extreme precipitation level (mm)')\n",
    "    plt.xlabel('Return period (years)')\n",
    "    plt.title(f'GEV intensity-frequency curves from predicted and observed')\n",
    "    plt.legend()\n",
    "    plt.savefig('../figures/GEV_pred_obs.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd8d79b-44f2-4977-aefc-7dabb6c8ae75",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_performance_rean(trained_models[name_of_best], X_val_rean, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef313fc7-8ac5-4173-8bab-388308260fc9",
   "metadata": {},
   "source": [
    "Under development: predictions from climate model data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bd8314-9855-4e10-a768-1f43bae65f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_gcm(model, X_val_gcm, X_fut_gcm):\n",
    "\n",
    "    # GCM VAL SET\n",
    "    print('> Predicting on the GCM validation set')\n",
    "    gcm_val_pred = model.predict(X_val_gcm)\n",
    "    print('> Recording performance metrics')\n",
    "\n",
    "    # Calculate Annual Precipitation Maxima 1995-2014\n",
    "    gcm_val_pred_apm = []\n",
    "    dpy = [365,366,365,365]*5 # days per year 1995 to 2014\n",
    "    for year in range(20):\n",
    "        idx_yearstart = sum(dpy[:year])\n",
    "        idx_nextyearstart = sum(dpy[:year+1])\n",
    "        gcm_val_pred_maxthisyear = max(gcm_val_pred[idx_yearstart:idx_nextyearstart])\n",
    "        gcm_val_pred_apm.append(gcm_val_pred_maxthisyear)\n",
    "\n",
    "    # GEV curves and implied flood levels\n",
    "    shape, loc, scale = gev.fit(gcm_val_pred_apm)\n",
    "    print('--> Return levels in millimeters, GEV of ML prediction from GCM historical run 1995-2014:')\n",
    "    one_pct_level_gcm_val_pred, four_pct_level_gcm_val_pred = gev.isf(1/100,shape,loc,scale), gev.isf(1/25,shape,loc,scale)\n",
    "    print('----> 1/100 year level:', one_pct_level_gcm_val_pred)\n",
    "    print('----> 1/25 year level:', four_pct_level_gcm_val_pred)\n",
    "\n",
    "\n",
    "\n",
    "    # GCM FUTURE SET\n",
    "    print('> Predicting on the GCM future set')\n",
    "    gcm_fut_pred = model.predict(X_fut_gcm)\n",
    "    print('> Recording performance metrics')\n",
    "\n",
    "    # Calculate Annual Precipitation Maxima 2031-2050\n",
    "    gcm_fut_pred_apm = []\n",
    "    dpy = [365,366,365,365]*5 # days per year 2031 to 2050\n",
    "    for year in range(20):\n",
    "        idx_yearstart = sum(dpy[:year])\n",
    "        idx_nextyearstart = sum(dpy[:year+1])\n",
    "        gcm_fut_pred_maxthisyear = max(gcm_fut_pred[idx_yearstart:idx_nextyearstart])\n",
    "        gcm_fut_pred_apm.append(gcm_fut_pred_maxthisyear)\n",
    "\n",
    "    # GEV curves and implied flood levels\n",
    "    shape, loc, scale = gev.fit(gcm_fut_pred_apm)\n",
    "    print('--> Return levels in millimeters, GEV of ML prediction from GCM projection 2031-2050:')\n",
    "    one_pct_level_gcm_fut_pred, four_pct_level_gcm_fut_pred = gev.isf(1/100,shape,loc,scale), gev.isf(1/25,shape,loc,scale)\n",
    "    print('----> 1/100 year level:', one_pct_level_gcm_fut_pred)\n",
    "    print('----> 1/25 year level:', four_pct_level_gcm_fut_pred)\n",
    "\n",
    "    return one_pct_level_gcm_fut_pred, four_pct_level_gcm_fut_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
